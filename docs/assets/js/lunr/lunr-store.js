var store = [{
        "title": "Awesome Timer",
        "excerpt":"Keep track of all of your awesome acts and share them wherever you’d like. You are what you repeatedly do, so it’s good to make sure you are not going too long between awesomeness!  ","categories": [],
        "tags": [],
        "url": "/apps/awesome-timer/",
        "teaser": "/assets/awesome-timer/mockup-th.png"
      },{
        "title": "No Place to Go",
        "excerpt":"I worked with the No Place to Go organizers and all 15 artists to create an app that enabled the socially distanced haunted house. The app coordinated the motion of single-car groups that rotated through five different locations. The app also reflected each artist’s (or artist group’s) vision for bringing more interactivity and context to their installations.   Source code available on GitHub.                                                                                                                                Selected screenshots from the app      ","categories": [],
        "tags": [],
        "url": "/apps/no-place-to-go/",
        "teaser": "/assets/no-place-to-go/mockup-th.png"
      },{
        "title": "So Much Coffee",
        "excerpt":"I believe there are no great tools to explore the world of coffee, so I set out to make my own. I took a product management approach to designing an app that lets users find the best coffee shops, discover roasters, and navigate roasts among other tasks. After a period of research, I developed this app for my thesis in Creative Technologies &amp; Design.   Source code available on GitHub.   Motivation &amp; Background   As a big coffee fan, I believe that there are so many things to enjoy about coffee besides just the caffeine in each of those beans. I wanted to get more into coffee in many ways, but it can quickly get very complicated to answer basic questions. Questions like:     Where is the closest coffee shop with great coffee?   How can I improve the coffee I make it home?   How do I explore the range of coffee flavors? There is no map to explore the complex world of coffee, which is why I set out to use my technical background, a product management approach, user-centered design, and an eye for detail to make loving coffee more accessible.   Problem Validation   I wanted to solve many problems with my design, but I felt that a coffee timer and a shop directory would be the most achievable with my time and skills, as well as line up the best with what users were looking for. I found out through interviewing that almost everyone has their own way of finding a coffee shop, but I was almost the only person looking for a better coffee brewing timer. When I need to narrow to scope of what I was building, I knew what to do.      Navigation &amp; User Flow   There can be as many entry points into the database as there are unique types of pages (see 1:1 vertical alignment in the middle) but some of these connections are still under development. Nonetheless, navigation between the different entities in the database allow for a long journey between shops, roasters, roasts, origins, and roasts. The graphic includes some planning ideas in orange and green.      Product Pitch   Main Pitch Deck   This is a modified version of the original product pitch I gave in my User-Centered Design class, spread across four slide decks for numerous supporting research slides.       Exemplars &amp; Competition   Nothing is perfect, but scanning through this collection reveals almost everything that I liked and wanted to emulate.       Mediocre || Unsure   The examples in the section all had some redeeming quality to them, but didn’t provide a great experience overall.       Weak Sauce   Everything in this category was seen as being a pretty bad example of what to do or how to execute on the problem. Interestingly, one of the apps included here is a daily driver app now, so nothing is absolute.      ","categories": [],
        "tags": [],
        "url": "/apps/so-much-coffee/",
        "teaser": "/assets/so-much-coffee/mockup-th.png"
      },{
        "title": "Web Example of Wild Camp Starting Context",
        "excerpt":"I came across a surprisingly good example of what I am trying to achieve in the R5 (Pacific Southwest Region) MVUM &amp; OSVUM Finder (and full-page equivalent) with my native iOS experience. The web experience is pretty bad, but the intended map discovery path (map rectangles on a larger map to place them in more useful context) is almost identical. What I can’t figure out is why I have not found an equivalent map for any other area in the United States.                  Screenshots of USFS tool showing MVUMs on larger California map  ","categories": ["Wild Camp"],
        "tags": ["mapping","MVUM","USFS"],
        "url": "/blog/web-example-mvum-collection/",
        "teaser": null
      },{
        "title": "GeoPDF to GeoJSON Basics",
        "excerpt":"The United States Forest Service (USFS) provides Motor Vehicle Use Maps (MVUMs) in GeoPDF (more) format. I would like to put the map rectangles on a MapKit map as an overlay, but the map extents in the PDF were difficult to get to.   I met a helpful resource in the Denver Devs community that pointed me toward the GDAL Python library. Between this library and the MyGeoData website, I was able to get the coordinates into a GeoJSON file in two ways.   Manually: Using MyGeoData Website   This website was great for finding out what I was dealing with, but I was limited to one file at a time, all manually. To get the GeoJSON, just upload the PDF and then select “Dataset Info”. The map extents were output as a rectangle (well, quadrilateral at least)in the following format.   {   \"type\": \"FeatureCollection\",   \"features\": [     {       \"type\": \"Feature\",       \"properties\": {},       \"geometry\": {         \"type\": \"Polygon\",         \"coordinates\": [           [             [-105.72891082981914, 39.7741391086867 ],             [-105.2340227421917 , 39.7741391086867 ],             [-105.2340227421917 , 40.07188076474783],             [-105.72891082981914, 40.07188076474783],             [-105.72891082981914, 39.7741391086867 ]           ]         ]       }     }   ] }   Scripted: Bash, Python, and GDAL   I had to automate the process and found that I could pull that same metadata from the PDF and save it to JSON in the terminal with   # for a GeoPDF named map.pdf and JSON output map.json gdalinfo map.pdf -json | tr -d '[:space:]' | grep -o' \"wgs84Extent\".*\\]\\]\\]\\}' &gt; map.json   which outputs (prettified afterward) the following content.   {   \"wgs84Extent\": {     \"type\": \"Polygon\",     \"coordinates\": [       [         [-105.7320528, 40.0698042],         [-105.7289108, 39.7741391],         [-105.2330182, 39.7761942],         [-105.2340227, 40.0718808],         [-105.7320528, 40.0698042]       ]     ]   } }   This works perfectly for most of the maps but   References      Convert GeoPDF with GDAL   Enable PDF Support in gdal   Other References      GDAL Library Website   osgeo4mac I don’t recall if I ever used this   QGIS is a wildly powerful app that I enjoyed but did not need  ","categories": ["Wild Camp"],
        "tags": ["mapping","GeoJSON","GeoPDF","Python","Bash","GDAL"],
        "url": "/blog/geopdf-to-geojson/",
        "teaser": null
      },{
        "title": "Create Directories for States and Forests",
        "excerpt":"To stay organized as I collect maps and extract data from them, I wanted to create a set of directories organizing every national forest within the state it is (primarily) contained within.   Collect Every Forest   I used two sources to create my list:     Complete List of American National Forests on Treehugger   List of national forests of the United States - Wikipedia   I then created a text file with all the raw data, looking like the content below in List of States and Forests.txt.  **Alabama** National Forests in Alabama **Alaska** Chugach National Forest Tongass National Forest **Arizona** Kaibab National Forest Coconino National Forest Prescott National Forest **Arkansas** Ozark St. Francis National Forest Ouachita National Forest **California** Angeles National Forest Cleveland National Forest Eldorado National Forest Inyo National Forest Klamath National Forest Lake Tahoe Basin Management Unit Lassen National Forest Los Padres National Forest Mendocino National Forest Modoc National Forest Plumas National Forest San Bernardino National Forest Sequoia National Forest Shasta-Trinity National Forest Sierra National Forest Six Rivers National Forest Stanislaus National Forest Tahoe National Forest **Colorado** Arapaho and Roosevelt National Forests &amp; Pawnee National Grassland Grand Mesa, Uncompahgre and Gunnison National Forests Medicine Bow-Routt National Forests Pike &amp; San Isabel National Forests, Cimarron &amp; Comanche National Grasslands Rio Grande National Forest San Juan National Forest White River National Forest **Florida** National Forests in Florida **Georgia** Chattahoochee-Oconee National Forests **Idaho** Boise National Forest Caribou-Targhee National Forest Idaho Panhandle National Forests Nez Perce-Clearwater National Forests Payette National Forest Salmon-Challis National Forest Sawtooth National Forest **Illinois** Midewin National Tallgrass Prairie Shawnee National Forest **Indiana** Hoosier National Forest **Kansas** Cimarron National Grassland **Kentucky** Daniel Boone National Forest Land Between The Lakes National Recreation Area **Louisiana** Kisatchie National Forest **Michigan** Hiawatha National Forest Huron-Manistee National Forests Ottawa National Forest **Minnesota** Chippewa National Forest Superior National Forest **Mississippi** National Forests in Mississippi **Missouri** Mark Twain National Forest **Montana** Beaverhead-Deerlodge National Forest Bitterroot National Forest Custer Gallatin National Forest Flathead National Forest Helena-Lewis and Clark National Forest Kootenai National Forest Lolo National Forest **Nebraska** Nebraska &amp; Samuel R. McKelvie National Forests - Buffalo Gap, Fort Pierre, &amp; Oglala National Grasslands **New Mexico** Cibola National Forest - Sandia RD Lincoln National Forest **North Carolina** National Forests in North Carolina **Nevada** Humbolt-Toiyabe National Forest **New Hampshire** White Mountain National Forest **New York** Finger Lakes National Forest **North Dakota** Dakota Prairie Grasslands **Ohio** Wayne National Forest **Oklahoma** Black Kettle and McClellan Creek National Grasslands Ouachita National Forest **Oregon** Columbia River Gorge National Scenic Area Crooked River National Grassland Fremont-Winema National Forest Deschutes National Forest Mt. Hood National Forest Ochoco National Forest Siuslaw National Forest Umatilla National Forest Willamette National Forest **Pennsylvania** Allegheny National Forest **South Carolina** Francis Marion National Forest Sumter National Forest **South Dakota** Buffalo Gap National Grassland Black Hills National Forest Dakota Prairie Grasslands Fort Pierre National Grassland **Tennessee** Cherokee National Forest **Texas** Black Kettle and McClellan Creek National Grasslands National Forests in Texas **Utah** Ashley National Forest Dixie National Forest Fishlake National Forest Manti-La Sal National Forest Unita-Wasatch-Cache National Forest **Vermont** Green Mountain National Forest **Virginia** George Washington and Jefferson National Forests **Washington** Colville National Forest Gifford Pinchot National Forest Mt. Baker-Snoqualmie National Forest Olympic National Forest **Wisconsin** Chequamegon-Nicolet National Forest **West Virginia** Monongahela National Forest **Wyoming** Bighorn National Forest Bridger-Teton National Forest Medicine Bow National Forest Shoshone National Forest Thunder Basin National Grassland   Make Directories   # MakeStateAndForestDirectories.py \"\"\"One directory per state, each state containing its forests\"\"\" import os  filename = \"List of States and Forests.txt\" with open(filename, 'r') as file: \tlines = file.read().splitlines() \tstate = \"\" \tfor line in lines: \t\tif line.find(\"**\") != -1: \t\t\tstate = line.replace(\"**\",\"\") \t\t\tos.mkdir(state) \t\telse: \t\t\tforest = line \t\t\ttry: \t\t\t\tos.mkdir(state + os.sep + forest) \t\t\texcept: \t\t\t\tos.mkdir(state + os.sep + forest + \" DUPLICATED\")  ","categories": ["Wild Camp"],
        "tags": ["Python"],
        "url": "/blog/forest-directories/",
        "teaser": null
      },{
        "title": "From GeoPDFs to Usable Data",
        "excerpt":"In a preceding post GeoJSON from GeoPDF we did some fast work to prove that we could get the data we need, but now we need to dig a little deeper to put it into a format that we think we can use.   All GeoPDF Content to JSON  Create JSON files containing all the data retrieved with the GDAL library with the script below.   # PDF2JSON.py \"\"\"Create a JSON of the same base filename of every PDF in the directory, recursively, in-place\"\"\"  import subprocess from glob import glob  filenames = glob(\"**/*.pdf\",recursive=True) for pdf in filenames: \tjson = pdf.replace(\"pdf\",\"json\") \twith open(json, 'w') as outfile: \t\tresult = subprocess.run([\"gdalinfo\",pdf,\"-json\"], stdout=subprocess.PIPE) \t\tout = result.stdout.decode(\"utf-8\") \t\toutfile.write(out)   Parse &amp; Reform Useful Parts  Convert the raw JSON files into parsed JSON files with the content that I want with the file below.   # Process Maps with Extents.py from glob import glob import json  filenames = glob(\"**/*.json\", recursive=True) failures = [] for json_filename in filenames:     if json_filename.find(\"parsed\") != -1:         continue     with open(json_filename, 'r') as file:         data = json.load(file)         try:             corners = data[\"wgs84Extent\"][\"coordinates\"][0]             lats = [lat for (_, lat) in corners[:-1]] # 5th point repeats first so slice             lngs = [lng for (lng, _) in corners[:-1]] # 5th point repeats first so slice              lat_avg = sum(lats) / float(len(lats))             lng_avg = sum(lngs) / float(len(lngs))              dict = {}             dict[\"center\"] = {                 \"latitude\": lat_avg,                 \"longitude\": lng_avg             }             for (lng, lat) in corners:                 if lng &lt; lng_avg and lat &gt; lat_avg:                     dict[\"northwest\"] = {                         \"latitude\": lat,                         \"longitude\": lng                     }                 elif lng &lt; lng_avg and lat &lt; lat_avg:                     dict[\"southwest\"] = {                         \"latitude\": lat,                         \"longitude\": lng                     }                 elif lng &gt; lng_avg and lat &gt; lat_avg:                     dict[\"northeast\"] = {                         \"latitude\": lat,                         \"longitude\": lng                     }                 elif lng &gt; lng_avg and lat &lt; lat_avg:                     dict[\"southeast\"] = {                         \"latitude\": lat,                         \"longitude\": lng                     }             # dict[\"rotationsCW\"] = 0             new_fn = json_filename.replace(\".json\",\"-parsed.json\")             content = json.dumps(dict, indent=4)             with open(new_fn, 'w') as new_file:                 new_file.write(content)         except:             failures.append(json_filename)  with open(\"parsing failed.txt\", 'w') as output:     output.writelines(\"%s\\n\" % l for l in failures)   List Missing Rectangles  Some files don’t give up their contents like the others, and they will need to be process manually later. We can get a list of the files with problems by running the script below.   # ListMissingLatLonExtent.py  import subprocess from glob import glob  missing = [] filenames = glob(\"**/*.json\", recursive=True) for json in filenames:     with open(json, 'r') as file:         str = file.read()         if str.find(\"wgs84Extent\") == -1 &amp; str.find(\"testing\") == -1:             missing.append(json)             print(json)  with open(\"missing rectangle.txt\", 'w') as output:     output.writelines(\"%s\\n\" % l for l in missing)   Final Usable Output  The final result of the JSON that I will use in the app looks like the example below, stelprdb5339604-parsed.json, which aligns with the raw filename of the GeoPDF. I have added a rotation property because some raw PDFs are not oriented with the North at the top, and I would rather not modify the source file every time it is updated, so I will track it in the JSON file.   {     \"center\": {         \"latitude\": 40.248042999999996,         \"longitude\": -106.0403644     },     \"northwest\": {         \"latitude\": 40.430488,         \"longitude\": -106.3666026     },     \"southwest\": {         \"latitude\": 40.0597988,         \"longitude\": -106.359167     },     \"southeast\": {         \"latitude\": 40.0655602,         \"longitude\": -105.7158853     },     \"northeast\": {         \"latitude\": 40.436325,         \"longitude\": -105.7198027     },     \"rotationsCW\": 0 }  ","categories": ["Wild Camp"],
        "tags": ["Python","gdal"],
        "url": "/blog/get-extents-for-all-geopds/",
        "teaser": null
      },{
        "title": "Regional MVUM Maps Everywhere",
        "excerpt":"In a previous post, I was puzzled about why I could not find more regional maps showing where the various MVUM maps were located. If “R5” was (for some reason) the Pacific Southwest, I figured there was a good chance that at least R1-R4 existed too, so I started digging around. An internet search for “R5 MVUM” took me to the full page R5 map that I added to the previous post. I then clicked on “Maps &amp; Publications” to get to https://www.fs.usda.gov/main/r5/maps-pubs. One link there got me to another full-page map for R4, and this had a URL clearly showing the region (https://www.fs.fed.us/mapfinder/?r=04).         The loading performance of these maps in Safari is incredibly bad and doesn’t always complete, but They have the right idea. In Chrome, they seem to be loading reliably.      R01: Northern Montana, North Dakota, Idaho   R02: Rocky Mountain Colorado, Kansas, Wyoming, South Dakota   R03: Southwest Arizona, New Mexico   R04: Intermountain Utah, Nevada, California overlaps   R05: Pacific Southwest California, Hawaii   R06: Pacific Northwest Oregon, Washington   R07: unspecified shows continental US, with map rectangles showing when zoomed   R08: Southern   R09: Eastern   R10: Alaska     ","categories": ["Wild Camp"],
        "tags": ["mapping","MVUM","USFS"],
        "url": "/blog/regional-mvum-maps-everywhere/",
        "teaser": null
      },{
    "title": "About",
    "excerpt":" ","url": "https://synodic.co/about/"
  },{
    "title": "Apps",
    "excerpt":" ","url": "https://synodic.co/apps/"
  },{
    "title": "Blog",
    "excerpt":" ","url": "https://synodic.co/blog/"
  },{
    "title": "Categories",
    "excerpt":" ","url": "https://synodic.co/blog/categories/"
  },{
    "title": "Contact",
    "excerpt":"   ","url": "https://synodic.co/contact/"
  },{
    "title": null,
    "excerpt":"","url": "https://synodic.co/"
  },{
    "title": null,
    "excerpt":"var idx = lunr(function () {   this.field('title')   this.field('excerpt')   this.field('categories')   this.field('tags')   this.ref('id')    this.pipeline.remove(lunr.trimmer)    for (var item in store) {     this.add({       title: store[item].title,       excerpt: store[item].excerpt,       categories: store[item].categories,       tags: store[item].tags,       id: item     })   } });  $(document).ready(function() {   $('input#search').on('keyup', function () {     var resultdiv = $('#results');     var query = $(this).val().toLowerCase();     var result =       idx.query(function (q) {         query.split(lunr.tokenizer.separator).forEach(function (term) {           q.term(term, { boost: 100 })           if(query.lastIndexOf(\" \") != query.length-1){             q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })           }           if (term != \"\"){             q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })           }         })       });     resultdiv.empty();     resultdiv.prepend(''+result.length+' Result(s) found ');     for (var item in result) {       var ref = result[item].ref;       if(store[ref].teaser){         var searchitem =           ''+             ''+               ''+                 ''+store[ref].title+''+               ' '+               ''+                 ''+               ''+               ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'... '+             ''+           '';       }       else{     \t  var searchitem =           ''+             ''+               ''+                 ''+store[ref].title+''+               ' '+               ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'... '+             ''+           '';       }       resultdiv.append(searchitem);     }   }); }); ","url": "https://synodic.co/assets/js/lunr/lunr-en.js"
  },{
    "title": null,
    "excerpt":"step1list = new Array(); step1list[\"ΦΑΓΙΑ\"] = \"ΦΑ\"; step1list[\"ΦΑΓΙΟΥ\"] = \"ΦΑ\"; step1list[\"ΦΑΓΙΩΝ\"] = \"ΦΑ\"; step1list[\"ΣΚΑΓΙΑ\"] = \"ΣΚΑ\"; step1list[\"ΣΚΑΓΙΟΥ\"] = \"ΣΚΑ\"; step1list[\"ΣΚΑΓΙΩΝ\"] = \"ΣΚΑ\"; step1list[\"ΟΛΟΓΙΟΥ\"] = \"ΟΛΟ\"; step1list[\"ΟΛΟΓΙΑ\"] = \"ΟΛΟ\"; step1list[\"ΟΛΟΓΙΩΝ\"] = \"ΟΛΟ\"; step1list[\"ΣΟΓΙΟΥ\"] = \"ΣΟ\"; step1list[\"ΣΟΓΙΑ\"] = \"ΣΟ\"; step1list[\"ΣΟΓΙΩΝ\"] = \"ΣΟ\"; step1list[\"ΤΑΤΟΓΙΑ\"] = \"ΤΑΤΟ\"; step1list[\"ΤΑΤΟΓΙΟΥ\"] = \"ΤΑΤΟ\"; step1list[\"ΤΑΤΟΓΙΩΝ\"] = \"ΤΑΤΟ\"; step1list[\"ΚΡΕΑΣ\"] = \"ΚΡΕ\"; step1list[\"ΚΡΕΑΤΟΣ\"] = \"ΚΡΕ\"; step1list[\"ΚΡΕΑΤΑ\"] = \"ΚΡΕ\"; step1list[\"ΚΡΕΑΤΩΝ\"] = \"ΚΡΕ\"; step1list[\"ΠΕΡΑΣ\"] = \"ΠΕΡ\"; step1list[\"ΠΕΡΑΤΟΣ\"] = \"ΠΕΡ\"; step1list[\"ΠΕΡΑΤΑ\"] = \"ΠΕΡ\"; step1list[\"ΠΕΡΑΤΩΝ\"] = \"ΠΕΡ\"; step1list[\"ΤΕΡΑΣ\"] = \"ΤΕΡ\"; step1list[\"ΤΕΡΑΤΟΣ\"] = \"ΤΕΡ\"; step1list[\"ΤΕΡΑΤΑ\"] = \"ΤΕΡ\"; step1list[\"ΤΕΡΑΤΩΝ\"] = \"ΤΕΡ\"; step1list[\"ΦΩΣ\"] = \"ΦΩ\"; step1list[\"ΦΩΤΟΣ\"] = \"ΦΩ\"; step1list[\"ΦΩΤΑ\"] = \"ΦΩ\"; step1list[\"ΦΩΤΩΝ\"] = \"ΦΩ\"; step1list[\"ΚΑΘΕΣΤΩΣ\"] = \"ΚΑΘΕΣΤ\"; step1list[\"ΚΑΘΕΣΤΩΤΟΣ\"] = \"ΚΑΘΕΣΤ\"; step1list[\"ΚΑΘΕΣΤΩΤΑ\"] = \"ΚΑΘΕΣΤ\"; step1list[\"ΚΑΘΕΣΤΩΤΩΝ\"] = \"ΚΑΘΕΣΤ\"; step1list[\"ΓΕΓΟΝΟΣ\"] = \"ΓΕΓΟΝ\"; step1list[\"ΓΕΓΟΝΟΤΟΣ\"] = \"ΓΕΓΟΝ\"; step1list[\"ΓΕΓΟΝΟΤΑ\"] = \"ΓΕΓΟΝ\"; step1list[\"ΓΕΓΟΝΟΤΩΝ\"] = \"ΓΕΓΟΝ\";  v = \"[ΑΕΗΙΟΥΩ]\"; v2 = \"[ΑΕΗΙΟΩ]\"  function stemWord(w) {   var stem;   var suffix;   var firstch;   var origword = w;   test1 = new Boolean(true);    if(w.length '+result.length+' Result(s) found ');     for (var item in result) {       var ref = result[item].ref;       if(store[ref].teaser){         var searchitem =           ''+             ''+               ''+                 ''+store[ref].title+''+               ' '+               ''+                 ''+               ''+               ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'... '+             ''+           '';       }       else{     \t  var searchitem =           ''+             ''+               ''+                 ''+store[ref].title+''+               ' '+               ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'... '+             ''+           '';       }       resultdiv.append(searchitem);     }   }); }); ","url": "https://synodic.co/assets/js/lunr/lunr-gr.js"
  },{
    "title": null,
    "excerpt":"var store = [   {%- for c in site.collections -%}     {%- if forloop.last -%}       {%- assign l = true -%}     {%- endif -%}     {%- assign docs = c.docs | where_exp:'doc','doc.search != false' -%}     {%- for doc in docs -%}       {%- if doc.header.teaser -%}         {%- capture teaser -%}{{ doc.header.teaser }}{%- endcapture -%}       {%- else -%}         {%- assign teaser = site.teaser -%}       {%- endif -%}       {         \"title\": {{ doc.title | jsonify }},         \"excerpt\":           {%- if site.search_full_content == true -%}             {{ doc.content | newline_to_br |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \"|             strip_html | strip_newlines | jsonify }},           {%- else -%}             {{ doc.content | newline_to_br |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \" |               replace:\" \", \" \"|             strip_html | strip_newlines | truncatewords: 50 | jsonify }},           {%- endif -%}         \"categories\": {{ doc.categories | jsonify }},         \"tags\": {{ doc.tags | jsonify }},         \"url\": {{ doc.url | relative_url | jsonify }},         \"teaser\": {{ teaser | relative_url | jsonify }}       }{%- unless forloop.last and l -%},{%- endunless -%}     {%- endfor -%}   {%- endfor -%}{%- if site.lunr.search_within_pages -%},   {%- assign pages = site.pages | where_exp:'doc','doc.search != false' -%}   {%- for doc in pages -%}     {%- if forloop.last -%}       {%- assign l = true -%}     {%- endif -%}   {     \"title\": {{ doc.title | jsonify }},     \"excerpt\":         {%- if site.search_full_content == true -%}           {{ doc.content | newline_to_br |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \"|           strip_html | strip_newlines | jsonify }},         {%- else -%}           {{ doc.content | newline_to_br |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \" |             replace:\" \", \" \"|           strip_html | strip_newlines | truncatewords: 50 | jsonify }},         {%- endif -%}       \"url\": {{ doc.url | absolute_url | jsonify }}   }{%- unless forloop.last and l -%},{%- endunless -%}   {%- endfor -%} {%- endif -%}] ","url": "https://synodic.co/assets/js/lunr/lunr-store.js"
  },{
    "title": "Tags",
    "excerpt":"","url": "https://synodic.co/blog/tags/"
  },{
    "title": null,
    "excerpt":" {% if page.xsl %} {% endif %} {% assign collections = site.collections | where_exp:'collection','collection.output != false' %}{% for collection in collections %}{% assign docs = collection.docs | where_exp:'doc','doc.sitemap != false' %}{% for doc in docs %} {{ doc.url | replace:'/index.html','/' | absolute_url | xml_escape }} {% if doc.last_modified_at or doc.date %}{{ doc.last_modified_at | default: doc.date | date_to_xmlschema }} {% endif %} {% endfor %}{% endfor %}{% assign pages = site.html_pages | where_exp:'doc','doc.sitemap != false' | where_exp:'doc','doc.url != \"/404.html\"' %}{% for page in pages %} {{ page.url | replace:'/index.html','/' | absolute_url | xml_escape }} {% if page.last_modified_at %}{{ page.last_modified_at | date_to_xmlschema }} {% endif %} {% endfor %}{% assign static_files = page.static_files | where_exp:'page','page.sitemap != false' | where_exp:'page','page.name != \"404.html\"' %}{% for file in static_files %} {{ file.path | replace:'/index.html','/' | absolute_url | xml_escape }} {{ file.modified_time | date_to_xmlschema }}  {% endfor %} ","url": "https://synodic.co/sitemap.xml"
  },{
    "title": null,
    "excerpt":"Sitemap: {{ \"sitemap.xml\" | absolute_url }} ","url": "https://synodic.co/robots.txt"
  },{
    "title": null,
    "excerpt":"{% if page.xsl %}{% endif %}Jekyll{{ site.time | date_to_xmlschema }}{{ page.url | absolute_url | xml_escape }}{% assign title = site.title | default: site.name %}{% if page.collection != \"posts\" %}{% assign collection = page.collection | capitalize %}{% assign title = title | append: \" | \" | append: collection %}{% endif %}{% if page.category %}{% assign category = page.category | capitalize %}{% assign title = title | append: \" | \" | append: category %}{% endif %}{% if title %}{{ title | smartify | xml_escape }}{% endif %}{% if site.description %}{{ site.description | xml_escape }}{% endif %}{% if site.author %}{{ site.author.name | default: site.author | xml_escape }}{% if site.author.email %}{{ site.author.email | xml_escape }}{% endif %}{% if site.author.uri %}{{ site.author.uri | xml_escape }}{% endif %}{% endif %}{% if page.tags %}{% assign posts = site.tags[page.tags] %}{% else %}{% assign posts = site[page.collection] %}{% endif %}{% if page.category %}{% assign posts = posts | where: \"categories\", page.category %}{% endif %}{% unless site.show_drafts %}{% assign posts = posts | where_exp: \"post\", \"post.draft != true\" %}{% endunless %}{% assign posts = posts | sort: \"date\" | reverse %}{% assign posts_limit = site.feed.posts_limit | default: 10 %}{% for post in posts limit: posts_limit %}{% assign post_title = post.title | smartify | strip_html | normalize_whitespace | xml_escape %}{{ post_title }}{{ post.date | date_to_xmlschema }}{{ post.last_modified_at | default: post.date | date_to_xmlschema }}{{ post.id | absolute_url | xml_escape }}{% assign excerpt_only = post.feed.excerpt_only | default: site.feed.excerpt_only %}{% unless excerpt_only %}{% endunless %}{% assign post_author = post.author | default: post.authors[0] | default: site.author %}{% assign post_author = site.data.authors[post_author] | default: post_author %}{% assign post_author_email = post_author.email | default: nil %}{% assign post_author_uri = post_author.uri | default: nil %}{% assign post_author_name = post_author.name | default: post_author %}{{ post_author_name | default: \"\" | xml_escape }}{% if post_author_email %}{{ post_author_email | xml_escape }}{% endif %}{% if post_author_uri %}{{ post_author_uri | xml_escape }}{% endif %}{% if post.category %}{% elsif post.categories %}{% for category in post.categories %}{% endfor %}{% endif %}{% for tag in post.tags %}{% endfor %}{% assign post_summary = post.description | default: post.excerpt %}{% if post_summary and post_summary != empty %}{% endif %}{% assign post_image = post.image.path | default: post.image %}{% if post_image %}{% unless post_image contains \"://\" %}{% assign post_image = post_image | absolute_url %}{% endunless %}{% endif %}{% endfor %}","url": "https://synodic.co/feed.xml"
  }]
